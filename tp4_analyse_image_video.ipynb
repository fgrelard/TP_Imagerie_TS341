{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7f02ff8-0d8d-4937-8152-7d45b91074df",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# TP 4 - Analyse d'images et de vidéos\n",
    "\n",
    "Dans ce TP, nous allons analyser et caractériser des images et vidéos.\n",
    "\n",
    "Ce TP est **noté**. Vous pouvez rendre votre code en m'envoyant le fichier Jupyter (format `ipynb`) par mail à `florent.grelard [at] u-bordeaux.fr`.\n",
    "\n",
    "Vous répondrez aux questions \"ouvertes\" (\"Que constatez-vous...?\", \"Pourquoi...?\", etc.) dans le TP par des commentaires dans votre code Python. Toutes tentatives et justifications pertinentes seront valorisées.\n",
    "\n",
    "Vous pouvez vous aider de toutes les fonctions numpy/skimage existantes. Si vous êtes bloqués à une question, vous pouvez utiliser les fonctions de ces bibliothèques pour passer aux questions suivantes.\n",
    "\n",
    "## 1. Détection d'objets\n",
    "\n",
    "Dans cet exercice, nous cherchons à détecter et isoler des objets. \n",
    "\n",
    "Nous allons extraire les **composantes connexes** de l'image afin d'extraire des mesures indépendamment pour chaque objet. Nous rappelons qu'une composante connexe est obtenue par **étiquetage** des pixels (*labelling* en anglais). Le principe est d'effectuer un **parcours en largeur** à partir d'un pixel objet (=255). Chaque pixel objet dans l'image est parcouru jusqu'à ce qu'ils soient tous étiquetés.\n",
    "\n",
    "Deux solutions pour le parcours en largeur:\n",
    "* Utilisation de la récursivité\n",
    "* Utilisation d'une pile\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "    <td>\n",
    "        <img src=\"data/obj_cc.png\" width=\"700\" /> \n",
    "        <figcaption style=\"text-align:center;\"> De gauche à droite: (a) Image originale, (b) Image de labels (chaque couleur correspond à un label différent) </figcaption>\n",
    "    </td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "**Exercice**: Compléter le code suivant:\n",
    "1. Compléter la fonction `eight_neighbours` qui extrait les coordonnées des 8-voisins d'un pixel.\n",
    "2. Compléter les fonctions `assign_label`, qui effectue le parcours en largeur et étiquète à partir d'**un pixel**, et  `connected_components`, qui étiquète l'**ensemble de l'image**. À l'issue du calcul, chaque composante connexe doit avoir un label différent.\n",
    "3. Les ballons possèdent un trou avec des pixels noirs. Quelle solution vue en cours pourrait être utilisée pour le combler?\n",
    "4. Une autre approche est d'utiliser `assign_label` en partant d'un pixel localisé dans un trou. Compléter la fonction `fill_holes`. Les coordonnées des pixels dans chaque trou sont données dans la variable `coords`. Appeler la fonction `fill_holes` **avant** d'effectuer l'étiquetage.\n",
    "5. (Facultatif) En cas de doute ou de difficulté, on pourra utiliser les fonctions `skimage.measure.label` (composantes connexes) et `scipy.ndimage.binary_fill_holes`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53c4928-40ba-4f1c-bd3f-2edae3bc821d",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import io\n",
    "from skimage import color\n",
    "from skimage import morphology\n",
    "from skimage import draw\n",
    "from skimage import transform\n",
    "\n",
    "def eight_neighbours(image, x, y):\n",
    "    \"\"\"\n",
    "    Coordonnées (x,y) pour le huit-voisinage\n",
    "    autour de x, y\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    region: list\n",
    "        Coordonnées (x, y) des 8 voisins du pixel\n",
    "        Longueur = 8\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "\n",
    "def assign_label(image, labelled_image, current_label, x, y):\n",
    "    \"\"\"\n",
    "    Parcours en largeur et etiquetage des\n",
    "    pixels objets\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    image: np.ndarray\n",
    "        image\n",
    "    labelled_image: np.ndarray\n",
    "        image de labels\n",
    "    current_label: int\n",
    "        label courant\n",
    "    x: int\n",
    "        coordonnée x\n",
    "    y: int\n",
    "        coordonnée y\n",
    "\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "\n",
    "def connected_components(image):\n",
    "    \"\"\"\n",
    "    Extrait l'ensemble des composantes\n",
    "    connexes dans une image\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    labelled_image: np.ndarray\n",
    "        image de labels\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "\n",
    "def fill_holes(image, coords):\n",
    "    \"\"\"\n",
    "    Comble les trous dans une image\n",
    "    à partir des coordonnées passées en paramètres\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "\n",
    "\n",
    "img_birds_rgb = io.imread(\"data/birds_sky.jpg\")\n",
    "img_birds = (color.rgb2gray(img_birds_rgb)*255).astype(np.uint8)\n",
    "\n",
    "img_threshold = np.where(img_birds < 30, 255, 0)\n",
    "\n",
    "coords = np.array([[254, 274], [206, 324], [106, 402]])\n",
    "\n",
    "fig, ax = plt.subplots(1, 2)\n",
    "ax[0].imshow(img_birds_rgb)\n",
    "[axi.set_axis_off() for axi in ax]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8be9bca-b63d-4d81-8232-742f98e8bfab",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 2. Caractérisation quantitative\n",
    "\n",
    "À ce stade, nous avons extrait et séparé les différents objets. Deux types d'objets sont toutefois présents dans l'image: des oiseaux et des ballons. Nous cherchons des mesures permettant de les discriminer.\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "    <td>\n",
    "        <img src=\"data/obj_mesure.png\" width=\"700\" /> \n",
    "        <figcaption style=\"text-align:center;\"> Classification des objets par des mesures: (a) Image des ballons, (b) Image des oiseaux </figcaption>\n",
    "    </td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "Voici quelques mesures qui peuvent être pertinentes:\n",
    "* L'aire : nombre de pixels dans la composante\n",
    "\n",
    "* Le périmètre : peut être (mal) estimé par le nombre de pixels dans le contour de la composante\n",
    "\n",
    "* La compacité: $C = \\dfrac{4 \\pi \\text{Aire}}{\\text{Périmètre}^2}$\n",
    "\n",
    "* La circularité $C_{box} = \\dfrac{4 \\pi \\text{Aire}}{\\text{Périmètre boite}^2}$\n",
    "\n",
    "* L'élongation : $E = \\dfrac{\\text{Longueur boite}}{\\text{Largeur boite}}$.\n",
    "\n",
    "$\\text{boite}$ : boîte englobante = le rectangle qui contient l'ensemble de l'objet.\n",
    "\n",
    "**Exercice**: Compléter le code suivant:\n",
    "1. Pourquoi le nombre total de pixels dans le contour est-il un mauvais estimateur du \"vrai\" périmètre? **NB.** Il existe de meilleurs estimateurs mais nous allons nous contenter de celui-ci pour ce TP.\n",
    "2. Compléter la fonction `bounding_box` qui calcule la boîte englobante autour d'un objet.\n",
    "3. Calculer les mesures qui vous semblent pertinentes pour discriminer les objets\n",
    "4. Classez les objets en générant deux images pour chaque type d'objet: oiseaux et ballons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0241ae-cd06-4126-a5c0-2c4dd9cb7457",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def bounding_box(image, label):\n",
    "    \"\"\"\n",
    "    Calcule la boîte englobante d'un objet\n",
    "    défini par son label\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    image: np.ndarray\n",
    "        image\n",
    "    label: int\n",
    "        le label de l'objet\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    rect: np.ndarray\n",
    "        le coin inférieur gauche et supérieur droit du rectangle\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "fig, ax = plt.subplots(1, 2)\n",
    "[axi.set_axis_off() for axi in ax]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d4eebd-c846-4440-9151-c6d251ef8ac0",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 3. Interaction avec une vidéo et soustraction de fond\n",
    "\n",
    "Dans cet exercice, vous allez interagir avec le flux vidéo de votre webcam, et manipuler la bibliothèque OpenCV.\n",
    "\n",
    "L'objectif principal est d'effectuer une **suppression de fond**. On rappelle que la suppression est faite par différence avec une image statique d'où les objets mouvants sont absents. Après seuillage, on peut remplacer les pixels de fond par ceux d'une image quelconque.\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "    <td>\n",
    "        <img src=\"data/suppression_fond_1.png\" width=\"350\" /> \n",
    "        <figcaption> Image d'arrière-plan </figcaption>\n",
    "    </td>\n",
    "    <td>\n",
    "        <img src=\"data/suppression_fond_vert.png\" width=\"350\" /> \n",
    "        <figcaption> Vidéo avec soustraction de fond </figcaption>\n",
    "    </td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "**Points pratiques**:\n",
    "* Les images couleur en OpenCV sont encodées dans l'ordre **BGR**... Prudence!\n",
    "* Pour quitter la vidéo, appuyer sur la touche Q.\n",
    "* Pour les personnes ne disposant pas de webcam, il est possible d'utiliser la vidéo `data/extrait_voyage_occident.mp4`.\n",
    "\n",
    "\n",
    "**Exercice**: Compléter le code suivant:\n",
    "1. Capturer une image sans objet mouvant. Cette capture peut être effectuée par un clic ou une entrée clavier quelconque.\n",
    "2. Compléter la fonction `background_subtraction` pour effectuer la suppression et le remplacement de fond. Attention au type (`uint8`) des images!\n",
    "3. (Facultatif) Détecter les visages dans le flux vidéo, en vous aidant de la documentation OpenCV. Les cascades de Haar (fichiers au format `xml`) sont stockées dans le répertoire `data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9889b7-da9c-430f-872f-6bc6407e7618",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "\n",
    "\n",
    "def background_subtraction(frame_after, frame_before, background, threshold):\n",
    "    \"\"\"\n",
    "    Suppression et remplacement\n",
    "    de fond\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    frame_after: np.ndarray\n",
    "        image courante du flux vidéo\n",
    "    frame_before: np.ndarray\n",
    "        image de référence sans objet mouvant\n",
    "    background: np.ndarray\n",
    "        image par laquelle remplacer les pixels statiques\n",
    "    threshold: int\n",
    "        seuil pour obtenir une image binaire fond/objet mouvant\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    frame: np.ndarray\n",
    "        image avec suppression de fond\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "def detect_faces(frame, face_cascade):\n",
    "    \"\"\"\n",
    "    Detection de visages\n",
    "    par les cascades de Haar\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "#Pour webcam:\n",
    "# vid = cv2.VideoCapture(0) ou vid = cv2.VideoCapture(-1)\n",
    "\n",
    "vid = cv2.VideoCapture(\"data/extrait_voyage_occident.mp4\")\n",
    "FPS = 30\n",
    "\n",
    "montagne = cv2.imread(\"data/montagne.jpg\")\n",
    "\n",
    "ret, first_image = vid.read()\n",
    "\n",
    "#Pour webcam:\n",
    "#while(True):\n",
    "\n",
    "while(vid.isOpened()):\n",
    "    # Capture the video frame by frame\n",
    "    ret, frame = vid.read()\n",
    "    if ret == False:\n",
    "        break\n",
    "\n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('frame', frame)\n",
    "    time.sleep(1/FPS)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "vid.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f2f24b-d0b2-412a-82d0-6cea12eee44c",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 4. Bonus - Transformée de Hough\n",
    "\n",
    "Nous souhaitons connaître l'équation des droites associées aux ficelles du ballon, afin d'extraire la longueur précise de chaque ficelle.\n",
    "\n",
    "Nous allons utiliser la **transformée de Hough** pour détecter les lignes. La transformée de Hough détecte les lignes dans un espace de paramètre $(\\rho, \\theta)$. \n",
    "\n",
    "Une droite a pour équation:\n",
    "\\begin{equation}\n",
    "    \\rho = x \\cos \\theta + y \\sin \\theta\n",
    "\\end{equation}\n",
    "\n",
    "Une ligne dans l'espace image devient un point dans l'espace de paramètre $(\\rho, \\theta)$. \n",
    "\n",
    "Un point dans l'espace image devient une sinusoïde dans l'espace de paramètre $(\\rho, \\theta)$. \n",
    "\n",
    "La transformée de Hough fonctionne par un système de **vote**, ou d'accumulation. On parcourt chaque pixel contour, et on trace sa sinusoïde dans $(\\rho, \\theta)$. A chaque passage par un pixel dans l'espace $(\\rho, \\theta)$, on incrémente sa valeur de 1.\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "    <td>\n",
    "        <img src=\"data/obj_hough.png\" width=\"700\" /> \n",
    "        <figcaption style=\"text-align:center;\"> De gauche à droite: (a) Image binaire, (b) Droites détectées par la transformée de Hough (en rouge) </figcaption>\n",
    "    </td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "**Exercice**: Compléter le code suivant:\n",
    "1. Compléter la fonction `hough_lines` qui calcule la transformée de Hough. Cette fonction retourne l'image d'accumulation dans l'espace $(\\rho, \\theta)$. L'axe $\\theta$ va de $0$ à $\\pi$ (subdivisions en 180 intervalles), et l'axe $\\rho$ de $0$ à $\\sqrt{L^2 + H^2}$ où $L$ et $H$ sont la largeur et la hauteur de l'image, respectivement.\n",
    "2. Filtrer l'image d'accumulation pour isoler les points majoritaires. Ces points correspondent aux lignes dans l'espace $(x, y)$.\n",
    "3. Utiliser la fonction `plt.axline` pour tracer les droites. Calculer les coordonées d'un point de départ avec les équations :$x_0 = \\rho * \\cos \\theta$ et $y_0 = \\rho \\sin \\theta$. La pente est donnée par $\\tan(-\\theta)$.\n",
    "4. Proposer une solution pour supprimer les droites redondantes.\n",
    "5. Grâce à l'équation des droites, calculer la longueur de chaque segment.\n",
    "6. (Facultatif) Comparer vos résultats avec les fonctions implémentées dans le module `skimage` pour la transformée de Hough."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab924492-d15b-4b5d-a395-8be78e772501",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def hough_lines(image):\n",
    "    \"\"\"\n",
    "    Détection des lignes par la transformée de Hough\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "def filter_hough(x_start, y_start, theta, dist):\n",
    "    \"\"\"\n",
    "    Filtrage de la transformée de Hough pour qu'il y ait un\n",
    "    espace minimal entre chaque ligne\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "\n",
    "img_threshold2 = np.where((img_birds > 50) & (img_birds < 52), 255, 0)\n",
    "\n",
    "fig, ax = plt.subplots(1, 2)\n",
    "ax[0].imshow(img_threshold2)\n",
    "[axi.set_axis_off() for axi in ax]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "argv": [
    "python",
    "-m",
    "ipykernel_launcher",
    "-f",
    "{connection_file}"
   ],
   "display_name": "Python 3 (ipykernel)",
   "env": null,
   "interrupt_mode": "signal",
   "language": "python",
   "metadata": {
    "debugger": true
   },
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "name": "tp4_analyse_image_video.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
